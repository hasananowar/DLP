{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.spatial.distance import cdist\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example DataFrame with columns X, Y, Z, Atom_Name, Residue_Name, Residue_ID, Atom_Type, and Timeframe\n",
    "# Load nodes for all timesteps\n",
    "filepath = \"/home/mhanowar/Downloads/HB1000frames.csv\"  # Replace with the actual file path\n",
    "data = pd.read_csv(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>Atom_Name</th>\n",
       "      <th>Residue_Name</th>\n",
       "      <th>Residue_ID</th>\n",
       "      <th>Atom_Type</th>\n",
       "      <th>time</th>\n",
       "      <th>node</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.759892</td>\n",
       "      <td>2.253709</td>\n",
       "      <td>33.260902</td>\n",
       "      <td>C1</td>\n",
       "      <td>CSP</td>\n",
       "      <td>1</td>\n",
       "      <td>cb</td>\n",
       "      <td>255000</td>\n",
       "      <td>C1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.862613</td>\n",
       "      <td>3.581455</td>\n",
       "      <td>34.023949</td>\n",
       "      <td>C2</td>\n",
       "      <td>CSP</td>\n",
       "      <td>1</td>\n",
       "      <td>cb</td>\n",
       "      <td>255000</td>\n",
       "      <td>C2_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.457548</td>\n",
       "      <td>4.321817</td>\n",
       "      <td>34.003315</td>\n",
       "      <td>C3</td>\n",
       "      <td>CSP</td>\n",
       "      <td>1</td>\n",
       "      <td>cb</td>\n",
       "      <td>255000</td>\n",
       "      <td>C3_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.981806</td>\n",
       "      <td>4.421790</td>\n",
       "      <td>32.537914</td>\n",
       "      <td>C4</td>\n",
       "      <td>CSP</td>\n",
       "      <td>1</td>\n",
       "      <td>cb</td>\n",
       "      <td>255000</td>\n",
       "      <td>C4_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.038748</td>\n",
       "      <td>3.091581</td>\n",
       "      <td>31.915064</td>\n",
       "      <td>O5</td>\n",
       "      <td>CSP</td>\n",
       "      <td>1</td>\n",
       "      <td>ob</td>\n",
       "      <td>255000</td>\n",
       "      <td>O5_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12247</th>\n",
       "      <td>22.502382</td>\n",
       "      <td>67.522812</td>\n",
       "      <td>49.062340</td>\n",
       "      <td>H8</td>\n",
       "      <td>SFL</td>\n",
       "      <td>14</td>\n",
       "      <td>ha</td>\n",
       "      <td>255001</td>\n",
       "      <td>H8_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12248</th>\n",
       "      <td>24.567900</td>\n",
       "      <td>66.078522</td>\n",
       "      <td>49.387047</td>\n",
       "      <td>H9</td>\n",
       "      <td>SFL</td>\n",
       "      <td>14</td>\n",
       "      <td>ha</td>\n",
       "      <td>255001</td>\n",
       "      <td>H9_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12249</th>\n",
       "      <td>20.595137</td>\n",
       "      <td>58.445484</td>\n",
       "      <td>53.666969</td>\n",
       "      <td>H10</td>\n",
       "      <td>SFL</td>\n",
       "      <td>14</td>\n",
       "      <td>ha</td>\n",
       "      <td>255001</td>\n",
       "      <td>H10_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12250</th>\n",
       "      <td>22.484032</td>\n",
       "      <td>60.872322</td>\n",
       "      <td>56.734215</td>\n",
       "      <td>H11</td>\n",
       "      <td>SFL</td>\n",
       "      <td>14</td>\n",
       "      <td>ha</td>\n",
       "      <td>255001</td>\n",
       "      <td>H11_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12251</th>\n",
       "      <td>21.801954</td>\n",
       "      <td>58.672573</td>\n",
       "      <td>55.999634</td>\n",
       "      <td>H12</td>\n",
       "      <td>SFL</td>\n",
       "      <td>14</td>\n",
       "      <td>ha</td>\n",
       "      <td>255001</td>\n",
       "      <td>H12_14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12252 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               X          Y          Z Atom_Name Residue_Name  Residue_ID  \\\n",
       "0      12.759892   2.253709  33.260902        C1          CSP           1   \n",
       "1      12.862613   3.581455  34.023949        C2          CSP           1   \n",
       "2      11.457548   4.321817  34.003315        C3          CSP           1   \n",
       "3      10.981806   4.421790  32.537914        C4          CSP           1   \n",
       "4      11.038748   3.091581  31.915064        O5          CSP           1   \n",
       "...          ...        ...        ...       ...          ...         ...   \n",
       "12247  22.502382  67.522812  49.062340        H8          SFL          14   \n",
       "12248  24.567900  66.078522  49.387047        H9          SFL          14   \n",
       "12249  20.595137  58.445484  53.666969       H10          SFL          14   \n",
       "12250  22.484032  60.872322  56.734215       H11          SFL          14   \n",
       "12251  21.801954  58.672573  55.999634       H12          SFL          14   \n",
       "\n",
       "      Atom_Type    time    node  \n",
       "0            cb  255000    C1_1  \n",
       "1            cb  255000    C2_1  \n",
       "2            cb  255000    C3_1  \n",
       "3            cb  255000    C4_1  \n",
       "4            ob  255000    O5_1  \n",
       "...         ...     ...     ...  \n",
       "12247        ha  255001   H8_14  \n",
       "12248        ha  255001   H9_14  \n",
       "12249        ha  255001  H10_14  \n",
       "12250        ha  255001  H11_14  \n",
       "12251        ha  255001  H12_14  \n",
       "\n",
       "[12252 rows x 9 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the dataframe based on Timeframe\n",
    "df = data.loc[data['Timeframe'] < 255002].copy()\n",
    "df.rename(columns={\"Timeframe\": \"time\"}, inplace=True)\n",
    "\n",
    "# Add a combined 'node' column\n",
    "df['node'] = df.apply(lambda row: f\"{row['Atom_Name']}_{row['Residue_ID']}\", axis=1)\n",
    "# Display the updated dataframe\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select rows where Residue_ID is 5 and Atom_Type is either 'o' or 'os'\n",
    "# df1 = df[(df['Residue_ID'] == 5) & df['Atom_Type'].isin(['o', 'os'])].reset_index(drop=True)\n",
    "# Select all O Atoms\n",
    "# Select relevant atom types and residue names for calculations\n",
    "df1 = df[df['Atom_Name'].str.startswith('O')].reset_index(drop=True)\n",
    "df2 = df[(df['Residue_Name'] == 'CSP') & (df['Atom_Type'] == 'n')].reset_index(drop=True)\n",
    "df3 = df[(df['Residue_Name'] == 'CSP') & (df['Atom_Type'] == 'hn')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def calculate_angle(vec1, vec2):\n",
    "    \"\"\"Calculate angle between two vectors.\"\"\"\n",
    "    cos_theta = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "    angle_rad = np.arccos(np.clip(cos_theta, -1.0, 1.0))\n",
    "    return np.degrees(angle_rad)\n",
    "\n",
    "def calculate_distance(row1, row2):\n",
    "    \"\"\"Calculate Euclidean distance.\"\"\"\n",
    "    return np.linalg.norm(np.array([row1.X, row1.Y, row1.Z]) - np.array([row2.X, row2.Y, row2.Z]))\n",
    "\n",
    "def process_results(df):\n",
    "    \"\"\"Process DataFrame to add molecular IDs, unique nh_id, and labels.\"\"\"\n",
    "    df['src_mol'] = df['src'].apply(lambda x: int(x.split('_')[1]))\n",
    "    df['dst_mol'] = df['dst'].apply(lambda x: int(x.split('_')[1]))\n",
    "    df['nh_id'] = pd.factorize(df['dst'])[0] + 1\n",
    "    df['label'] = np.where(\n",
    "        (df['src_mol'].between(5, 14)) & (df['dst_mol'].between(1, 4)), 2, 1\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# Function to process DataFrame and save it to a CSV file\n",
    "def process_and_save_dataframe(df, filename):\n",
    "    \"\"\"\n",
    "    Process the input DataFrame to add 'ext_roll' and 'idx' columns.\n",
    "    Save the processed DataFrame to a specified CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame\n",
    "    - filename (str): Output file path\n",
    "    \"\"\"\n",
    "    num_rows = len(df)\n",
    "\n",
    "    # Initialize 'ext_roll' column with zeros\n",
    "    df['ext_roll'] = 0\n",
    "\n",
    "    # Assign 1 to the middle 15% rows and 2 to the last 15% rows\n",
    "    df.loc[int(num_rows * 0.7):int(num_rows * 0.85) - 1, 'ext_roll'] = 1\n",
    "    df.loc[int(num_rows * 0.85):, 'ext_roll'] = 2\n",
    "\n",
    "    # Insert an 'idx' column at the beginning\n",
    "    df.insert(0, 'idx', range(len(df)))\n",
    "\n",
    "    # Reindex and retain only the required columns\n",
    "    df = df[['idx', 'src', 'dst', 'time', 'label', 'ext_roll', 'nh_id']]\n",
    "\n",
    "    # Save the updated DataFrame to the specified CSV file\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Saved updated DataFrame to {filename}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          src     dst    time   distance  src_mol  dst_mol  nh_id  label\n",
      "0        O5_1   N11_1  255000   4.435484        1        1      1      1\n",
      "1        O5_1   N23_1  255000   5.677049        1        1      2      1\n",
      "2        O5_1   N35_1  255000   6.328246        1        1      3      1\n",
      "3        O5_1   N55_1  255000   6.667776        1        1      4      1\n",
      "4        O5_1   N67_1  255000   7.467732        1        1      5      1\n",
      "...       ...     ...     ...        ...      ...      ...    ...    ...\n",
      "257467  O2_14  N727_4  255001  80.193537       14        4    212      2\n",
      "257468  O2_14  N739_4  255001  76.475652       14        4    213      2\n",
      "257469  O2_14  N759_4  255001  76.042337       14        4    214      2\n",
      "257470  O2_14  N771_4  255001  85.641525       14        4    215      2\n",
      "257471  O2_14  N783_4  255001  84.852530       14        4    216      2\n",
      "\n",
      "[257472 rows x 8 columns]\n",
      "          src     dst    time       angle  src_mol  dst_mol  nh_id  label\n",
      "0        O5_1    H9_1  255000   61.040505        1        1      1      1\n",
      "1        O5_1   H19_1  255000   73.524710        1        1      2      1\n",
      "2        O5_1   H29_1  255000   88.194570        1        1      3      1\n",
      "3        O5_1   H46_1  255000  120.540965        1        1      4      1\n",
      "4        O5_1   H56_1  255000  115.887955        1        1      5      1\n",
      "...       ...     ...     ...         ...      ...      ...    ...    ...\n",
      "257467  O2_14  H611_4  255001  161.329513       14        4    212      2\n",
      "257468  O2_14  H621_4  255001   52.233228       14        4    213      2\n",
      "257469  O2_14  H638_4  255001   91.340280       14        4    214      2\n",
      "257470  O2_14  H648_4  255001  124.377794       14        4    215      2\n",
      "257471  O2_14  H658_4  255001   92.171690       14        4    216      2\n",
      "\n",
      "[257472 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate angles and distances\n",
    "distance_results = []\n",
    "angle_results = []\n",
    "\n",
    "for t in df1['time'].unique():\n",
    "    df1_time = df1[df1['time'] == t].reset_index(drop=True)\n",
    "    df2_time = df2[df2['time'] == t].reset_index(drop=True)\n",
    "    df3_time = df3[df3['time'] == t].reset_index(drop=True)\n",
    "\n",
    "    for row1 in df1_time.itertuples(index=False):\n",
    "        for idx, row3 in df3_time.iterrows():\n",
    "            if idx < len(df2_time):\n",
    "                row2 = df2_time.loc[idx]\n",
    "\n",
    "                # Vectors and calculations\n",
    "                vec3_to_df1 = np.array([row1.X - row3.X, row1.Y - row3.Y, row1.Z - row3.Z])\n",
    "                vec3_to_df2 = np.array([row2['X'] - row3.X, row2['Y'] - row3.Y, row2['Z'] - row3.Z])\n",
    "                angle = calculate_angle(vec3_to_df1, vec3_to_df2)\n",
    "                distance = calculate_distance(row1, row2)\n",
    "\n",
    "                # Append results\n",
    "                distance_results.append({'src': row1.node, 'dst': row2['node'], 'time': t, 'distance': distance})\n",
    "                angle_results.append({'src': row1.node, 'dst': row3['node'], 'time': t, 'angle': angle})\n",
    "\n",
    "# Convert results to DataFrames\n",
    "dist_df = process_results(pd.DataFrame(distance_results))\n",
    "angle_df = process_results(pd.DataFrame(angle_results))\n",
    "\n",
    "# Display DataFrames\n",
    "print(dist_df)\n",
    "print(angle_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Distance DataFrame:\n",
      "       src  dst    time   distance  src_mol  dst_mol  nh_id  label\n",
      "0        0  586  255000   4.435484        1        1      1      1\n",
      "1        0  587  255000   5.677049        1        1      2      1\n",
      "2        0  588  255000   6.328246        1        1      3      1\n",
      "3        0  589  255000   6.667776        1        1      4      1\n",
      "4        0  590  255000   7.467732        1        1      5      1\n",
      "...    ...  ...     ...        ...      ...      ...    ...    ...\n",
      "24388  585  742  255001  13.913711       12        4    176      2\n",
      "24389  585  738  255001  12.650958       12        4    177      2\n",
      "24390  585  746  255001  11.569930       12        4    179      2\n",
      "24391  585  741  255001   7.632603       12        4    180      2\n",
      "24392  585  743  255001  12.214476       12        4    181      2\n",
      "\n",
      "[24393 rows x 8 columns]\n",
      "\n",
      "Filtered Angle DataFrame:\n",
      "   src  dst    time       angle  src_mol  dst_mol  nh_id  label\n",
      "0    0  812  255000  120.540965        1        1      4      1\n",
      "1    0  813  255000  115.887955        1        1      5      1\n",
      "2    0  814  255000  172.370689        1        1      7      1\n",
      "3    0  815  255000  151.039706        1        1     15      1\n",
      "4    0  816  255000  167.839722        1        1     16      1\n"
     ]
    }
   ],
   "source": [
    "# Filter and label the distance DataFrame\n",
    "filtered_dist_df = dist_df[dist_df['distance'] <= 15].copy()\n",
    "filtered_dist_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Filter and label the angle DataFrame\n",
    "filtered_angle_df = angle_df[(angle_df['angle'] >= 105) & (angle_df['angle'] < 180)].copy()\n",
    "filtered_angle_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Combine src and dst values for consistent mapping\n",
    "combined_values = pd.concat([\n",
    "    filtered_dist_df['src'], filtered_dist_df['dst'], \n",
    "    filtered_angle_df['src'], filtered_angle_df['dst']\n",
    "])\n",
    "\n",
    "# Use factorize to assign numeric indices\n",
    "numeric_indices, _ = pd.factorize(combined_values)\n",
    "\n",
    "# Map src and dst directly to numeric indices using factorized output\n",
    "mapping = pd.Series(numeric_indices, index=combined_values).to_dict()\n",
    "\n",
    "# Replace src and dst with numeric indices\n",
    "for df in [filtered_dist_df, filtered_angle_df]:\n",
    "    df['src'] = df['src'].map(mapping)\n",
    "    df['dst'] = df['dst'].map(mapping)\n",
    "\n",
    "# Display the filtered DataFrames\n",
    "print(\"Filtered Distance DataFrame:\")\n",
    "print(filtered_dist_df)\n",
    "\n",
    "print(\"\\nFiltered Angle DataFrame:\")\n",
    "print(filtered_angle_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved updated DataFrame to DATA/HB/edges1.csv\n",
      "Saved updated DataFrame to DATA/HB/edges2.csv\n",
      "Updated Distance DataFrame:\n",
      "<bound method NDFrame.head of          idx  src  dst    time  label  ext_roll  nh_id\n",
      "0          0    0  586  255000      1         0      1\n",
      "1          1    0  587  255000      1         0      2\n",
      "2          2    0  588  255000      1         0      3\n",
      "3          3    0  589  255000      1         0      4\n",
      "4          4    0  590  255000      1         0      5\n",
      "...      ...  ...  ...     ...    ...       ...    ...\n",
      "24388  24388  585  742  255001      2         2    176\n",
      "24389  24389  585  738  255001      2         2    177\n",
      "24390  24390  585  746  255001      2         2    179\n",
      "24391  24391  585  741  255001      2         2    180\n",
      "24392  24392  585  743  255001      2         2    181\n",
      "\n",
      "[24393 rows x 7 columns]>\n",
      "\n",
      "Updated Angle DataFrame:\n",
      "   idx  src  dst    time  label  ext_roll  nh_id\n",
      "0    0    0  812  255000      1         0      4\n",
      "1    1    0  813  255000      1         0      5\n",
      "2    2    0  814  255000      1         0      7\n",
      "3    3    0  815  255000      1         0     15\n",
      "4    4    0  816  255000      1         0     16\n"
     ]
    }
   ],
   "source": [
    "# Process and save distance DataFrame\n",
    "final_dist_df = process_and_save_dataframe(filtered_dist_df, 'DATA/HB/edges1.csv')\n",
    "\n",
    "# Process and save angle DataFrame\n",
    "final_angle_df = process_and_save_dataframe(filtered_angle_df, 'DATA/HB/edges2.csv')\n",
    "\n",
    "# Display the first few rows of both DataFrames\n",
    "print(\"Updated Distance DataFrame:\")\n",
    "print(final_dist_df.head)\n",
    "\n",
    "print(\"\\nUpdated Angle DataFrame:\")\n",
    "print(final_angle_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract src and dst column features\n",
    "# src_feats = filtered_df[['src', 'src_mol']].rename(columns={'src': 'node', 'src_mol': 'mol'})\n",
    "# dst_feats = filtered_df[['dst', 'dst_mol']].rename(columns={'dst': 'node', 'dst_mol': 'mol'})\n",
    "\n",
    "# # Concatenate src and dst features\n",
    "# node_feats = pd.concat([src_feats, dst_feats])\n",
    "\n",
    "# # Drop duplicates\n",
    "# node_feats = node_feats.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# # Save to CSV\n",
    "# node_feats.to_csv('DATA/HB/node_feats.csv', index=False)\n",
    "\n",
    "# # Display the node features\n",
    "# print(node_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Encode nodes into unique integers\n",
    "# le_node = LabelEncoder()\n",
    "\n",
    "# # Fit the encoder on the combined 'src' and 'dst' columns from both dataframes\n",
    "# all_nodes = pd.concat([filtered_dist_df['src'], filtered_dist_df['dst'], filtered_angle_df['src'], filtered_angle_df['dst']])\n",
    "# le_node.fit(all_nodes)\n",
    "\n",
    "# # Transform the 'src' and 'dst' columns in both dataframes\n",
    "# filtered_dist_df['src'] = le_node.transform(filtered_dist_df['src'])\n",
    "# filtered_dist_df['dst'] = le_node.transform(filtered_dist_df['dst']) + filtered_dist_df['src'].max() + 1\n",
    "\n",
    "# filtered_angle_df['src'] = le_node.transform(filtered_angle_df['src'])\n",
    "# filtered_angle_df['dst'] = le_node.transform(filtered_angle_df['dst']) + filtered_angle_df['src'].max() + 1\n",
    "\n",
    "# # Display the first few rows of each dataframe\n",
    "# print(filtered_dist_df)\n",
    "# print(filtered_angle_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get unique nodes from node_1, node_2, and node_3 columns\n",
    "# unique_nodes_1 = filtered_df['src'].unique()\n",
    "# unique_nodes_2 = filtered_df['dst'].unique()\n",
    "\n",
    "# # Assign a color for each group (e.g., tab10 colormap)\n",
    "# color_1 = plt.cm.tab10(0)  # Color for node_1 group\n",
    "# color_2 = plt.cm.tab10(1)  # Color for node_2 group\n",
    "# color_3 = plt.cm.tab10(2)  # Color for node_3 group\n",
    "\n",
    "# # Create a combined color map based on the node groups\n",
    "# node_colors = {}\n",
    "# for node in unique_nodes_1:\n",
    "#     node_colors[node] = color_1\n",
    "# for node in unique_nodes_2:\n",
    "#     node_colors[node] = color_2\n",
    "\n",
    "\n",
    "# # Create a graph\n",
    "# G = nx.Graph()\n",
    "\n",
    "# # Add edges between node_1 and node_2\n",
    "# edges_1_2 = filtered_df[['node_1', 'node_2']].values.tolist()\n",
    "# G.add_edges_from(edges_1_2)\n",
    "\n",
    "# # Add edges between node_1 and node_3\n",
    "# edges_1_3 = filtered_df[['node_1', 'node_3']].values.tolist()\n",
    "# G.add_edges_from(edges_1_3)\n",
    "\n",
    "# # Add edges between node_2 and node_3 (these will be bold)\n",
    "# edges_2_3 = filtered_df[['node_2', 'node_3']].values.tolist()\n",
    "# G.add_edges_from(edges_2_3)\n",
    "\n",
    "# # Define the layout for the graph\n",
    "# pos = nx.spring_layout(G)\n",
    "\n",
    "# # Separate edges into normal and bold\n",
    "# normal_edges = edges_1_2 + edges_1_3\n",
    "# bold_edges = edges_2_3\n",
    "\n",
    "# # Plot the graph\n",
    "# plt.figure(figsize=(8, 4))\n",
    "# nx.draw(\n",
    "#     G,\n",
    "#     pos,\n",
    "#     with_labels=True,\n",
    "#     node_size=500,\n",
    "#     node_color=[node_colors[node] for node in G.nodes()],\n",
    "#     font_size=10,\n",
    "#     font_weight='bold',\n",
    "#     edge_color='gray',\n",
    "#     edgelist=normal_edges,\n",
    "#     width=1  # Normal edges width\n",
    "# )\n",
    "\n",
    "# # Draw the bold edges separately\n",
    "# nx.draw_networkx_edges(\n",
    "#     G,\n",
    "#     pos,\n",
    "#     edgelist=bold_edges,\n",
    "#     width=2,  # Bold edges width\n",
    "#     edge_color='black'\n",
    "# )\n",
    "\n",
    "# plt.title('Graph')\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphenv",
   "language": "python",
   "name": "graphenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
