{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.spatial.distance import cdist\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example DataFrame with columns X, Y, Z, Atom_Name, Residue_Name, Residue_ID, Atom_Type, and Timeframe\n",
    "# Load nodes for all timesteps\n",
    "filepath = \"/home/mhanowar/Downloads/HB1000frames.csv\"  # Replace with the actual file path\n",
    "data = pd.read_csv(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>Atom_Name</th>\n",
       "      <th>Residue_Name</th>\n",
       "      <th>Residue_ID</th>\n",
       "      <th>Atom_Type</th>\n",
       "      <th>time</th>\n",
       "      <th>node</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.759892</td>\n",
       "      <td>2.253709</td>\n",
       "      <td>33.260902</td>\n",
       "      <td>C1</td>\n",
       "      <td>CSP</td>\n",
       "      <td>1</td>\n",
       "      <td>cb</td>\n",
       "      <td>255000</td>\n",
       "      <td>C1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.862613</td>\n",
       "      <td>3.581455</td>\n",
       "      <td>34.023949</td>\n",
       "      <td>C2</td>\n",
       "      <td>CSP</td>\n",
       "      <td>1</td>\n",
       "      <td>cb</td>\n",
       "      <td>255000</td>\n",
       "      <td>C2_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.457548</td>\n",
       "      <td>4.321817</td>\n",
       "      <td>34.003315</td>\n",
       "      <td>C3</td>\n",
       "      <td>CSP</td>\n",
       "      <td>1</td>\n",
       "      <td>cb</td>\n",
       "      <td>255000</td>\n",
       "      <td>C3_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.981806</td>\n",
       "      <td>4.421790</td>\n",
       "      <td>32.537914</td>\n",
       "      <td>C4</td>\n",
       "      <td>CSP</td>\n",
       "      <td>1</td>\n",
       "      <td>cb</td>\n",
       "      <td>255000</td>\n",
       "      <td>C4_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.038748</td>\n",
       "      <td>3.091581</td>\n",
       "      <td>31.915064</td>\n",
       "      <td>O5</td>\n",
       "      <td>CSP</td>\n",
       "      <td>1</td>\n",
       "      <td>ob</td>\n",
       "      <td>255000</td>\n",
       "      <td>O5_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36751</th>\n",
       "      <td>21.767370</td>\n",
       "      <td>65.705544</td>\n",
       "      <td>49.322563</td>\n",
       "      <td>H8</td>\n",
       "      <td>SFL</td>\n",
       "      <td>14</td>\n",
       "      <td>ha</td>\n",
       "      <td>255005</td>\n",
       "      <td>H8_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36752</th>\n",
       "      <td>22.807545</td>\n",
       "      <td>63.486736</td>\n",
       "      <td>48.436836</td>\n",
       "      <td>H9</td>\n",
       "      <td>SFL</td>\n",
       "      <td>14</td>\n",
       "      <td>ha</td>\n",
       "      <td>255005</td>\n",
       "      <td>H9_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36753</th>\n",
       "      <td>19.063622</td>\n",
       "      <td>56.540447</td>\n",
       "      <td>53.720280</td>\n",
       "      <td>H10</td>\n",
       "      <td>SFL</td>\n",
       "      <td>14</td>\n",
       "      <td>ha</td>\n",
       "      <td>255005</td>\n",
       "      <td>H10_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36754</th>\n",
       "      <td>22.261448</td>\n",
       "      <td>58.099701</td>\n",
       "      <td>56.088982</td>\n",
       "      <td>H11</td>\n",
       "      <td>SFL</td>\n",
       "      <td>14</td>\n",
       "      <td>ha</td>\n",
       "      <td>255005</td>\n",
       "      <td>H11_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36755</th>\n",
       "      <td>20.704792</td>\n",
       "      <td>56.193008</td>\n",
       "      <td>55.509266</td>\n",
       "      <td>H12</td>\n",
       "      <td>SFL</td>\n",
       "      <td>14</td>\n",
       "      <td>ha</td>\n",
       "      <td>255005</td>\n",
       "      <td>H12_14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36756 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               X          Y          Z Atom_Name Residue_Name  Residue_ID  \\\n",
       "0      12.759892   2.253709  33.260902        C1          CSP           1   \n",
       "1      12.862613   3.581455  34.023949        C2          CSP           1   \n",
       "2      11.457548   4.321817  34.003315        C3          CSP           1   \n",
       "3      10.981806   4.421790  32.537914        C4          CSP           1   \n",
       "4      11.038748   3.091581  31.915064        O5          CSP           1   \n",
       "...          ...        ...        ...       ...          ...         ...   \n",
       "36751  21.767370  65.705544  49.322563        H8          SFL          14   \n",
       "36752  22.807545  63.486736  48.436836        H9          SFL          14   \n",
       "36753  19.063622  56.540447  53.720280       H10          SFL          14   \n",
       "36754  22.261448  58.099701  56.088982       H11          SFL          14   \n",
       "36755  20.704792  56.193008  55.509266       H12          SFL          14   \n",
       "\n",
       "      Atom_Type    time    node  \n",
       "0            cb  255000    C1_1  \n",
       "1            cb  255000    C2_1  \n",
       "2            cb  255000    C3_1  \n",
       "3            cb  255000    C4_1  \n",
       "4            ob  255000    O5_1  \n",
       "...         ...     ...     ...  \n",
       "36751        ha  255005   H8_14  \n",
       "36752        ha  255005   H9_14  \n",
       "36753        ha  255005  H10_14  \n",
       "36754        ha  255005  H11_14  \n",
       "36755        ha  255005  H12_14  \n",
       "\n",
       "[36756 rows x 9 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the dataframe based on Timeframe\n",
    "df = data.loc[data['Timeframe'] < 255006].copy()\n",
    "df.rename(columns={\"Timeframe\": \"time\"}, inplace=True)\n",
    "\n",
    "# Add a combined 'node' column\n",
    "df['node'] = df.apply(lambda row: f\"{row['Atom_Name']}_{row['Residue_ID']}\", axis=1)\n",
    "# Display the updated dataframe\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select rows where Residue_ID is 5 and Atom_Type is either 'o' or 'os'\n",
    "# df1 = df[(df['Residue_ID'] == 5) & df['Atom_Type'].isin(['o', 'os'])].reset_index(drop=True)\n",
    "# Select all O Atoms\n",
    "# Select relevant atom types and residue names for calculations\n",
    "df1 = df[df['Atom_Name'].str.startswith('O')].reset_index(drop=True)\n",
    "df2 = df[(df['Residue_Name'] == 'CSP') & (df['Atom_Type'] == 'n')].reset_index(drop=True)\n",
    "df3 = df[(df['Residue_Name'] == 'CSP') & (df['Atom_Type'] == 'hn')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def calculate_angle(vec1, vec2):\n",
    "    \"\"\"Calculate angle between two vectors.\"\"\"\n",
    "    cos_theta = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "    angle_rad = np.arccos(np.clip(cos_theta, -1.0, 1.0))\n",
    "    return np.degrees(angle_rad)\n",
    "\n",
    "def calculate_distance(row1, row2):\n",
    "    \"\"\"Calculate Euclidean distance.\"\"\"\n",
    "    return np.linalg.norm(np.array([row1.X, row1.Y, row1.Z]) - np.array([row2.X, row2.Y, row2.Z]))\n",
    "\n",
    "def process_results(df):\n",
    "    \"\"\"Process DataFrame to add molecular IDs, unique nh_id, and labels.\"\"\"\n",
    "    df['src_mol'] = df['src'].apply(lambda x: int(x.split('_')[1]))\n",
    "    df['dst_mol'] = df['dst'].apply(lambda x: int(x.split('_')[1]))\n",
    "    df['nh_id'] = pd.factorize(df['dst'])[0] + 1\n",
    "    df['label'] = np.where(\n",
    "        (df['src_mol'].between(5, 14)) & (df['dst_mol'].between(1, 4)), 2, 1\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# Function to process DataFrame and save it to a CSV file\n",
    "def process_and_save_dataframe(df, filename):\n",
    "    \"\"\"\n",
    "    Process the input DataFrame to add 'ext_roll' and 'idx' columns.\n",
    "    Convert all columns to integers before saving.\n",
    "    Save the processed DataFrame to a specified CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame\n",
    "    - filename (str): Output file path\n",
    "    \"\"\"\n",
    "    num_rows = len(df)\n",
    "\n",
    "    # Initialize 'ext_roll' column with zeros\n",
    "    df['ext_roll'] = 0\n",
    "\n",
    "    # Assign 1 to the middle 15% rows and 2 to the last 15% rows\n",
    "    df.loc[int(num_rows * 0.7):int(num_rows * 0.85) - 1, 'ext_roll'] = 1\n",
    "    df.loc[int(num_rows * 0.85):, 'ext_roll'] = 2\n",
    "\n",
    "    # Insert an 'idx' column at the beginning\n",
    "    df.insert(0, 'idx', range(len(df)))\n",
    "\n",
    "    # Reindex and retain only the required columns\n",
    "    df = df[['idx', 'src', 'dst', 'time', 'label', 'ext_roll', 'nh_id']]\n",
    "\n",
    "    # Convert all columns to integers\n",
    "    for col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Save the updated DataFrame to the specified CSV file\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Saved updated DataFrame to {filename}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate angles and distances\n",
    "distance_results = []\n",
    "angle_results = []\n",
    "\n",
    "for t in df1['time'].unique():\n",
    "    df1_time = df1[df1['time'] == t].reset_index(drop=True)\n",
    "    df2_time = df2[df2['time'] == t].reset_index(drop=True)\n",
    "    df3_time = df3[df3['time'] == t].reset_index(drop=True)\n",
    "\n",
    "    for row1 in df1_time.itertuples(index=False):\n",
    "        for idx, row3 in df3_time.iterrows():\n",
    "            if idx < len(df2_time):\n",
    "                row2 = df2_time.loc[idx]\n",
    "\n",
    "                # Vectors and calculations\n",
    "                vec3_to_df1 = np.array([row1.X - row3.X, row1.Y - row3.Y, row1.Z - row3.Z])\n",
    "                vec3_to_df2 = np.array([row2['X'] - row3.X, row2['Y'] - row3.Y, row2['Z'] - row3.Z])\n",
    "                angle = calculate_angle(vec3_to_df1, vec3_to_df2)\n",
    "                distance = calculate_distance(row1, row2)\n",
    "\n",
    "                # Append results\n",
    "                distance_results.append({'src': row1.node, 'dst': row2['node'], 'time': t, 'distance': distance})\n",
    "                angle_results.append({'src': row1.node, 'dst': row3['node'], 'time': t, 'angle': angle})\n",
    "\n",
    "# Convert results to DataFrames\n",
    "dist_df = process_results(pd.DataFrame(distance_results))\n",
    "angle_df = process_results(pd.DataFrame(angle_results))\n",
    "\n",
    "# Display DataFrames\n",
    "print(dist_df)\n",
    "print(angle_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Distance DataFrame:\n",
      "       src  dst    time   distance  src_mol  dst_mol  nh_id  label\n",
      "0        0  586  255000   4.435484        1        1      1      1\n",
      "1        0  587  255000   5.677049        1        1      2      1\n",
      "2        0  588  255000   6.328246        1        1      3      1\n",
      "3        0  589  255000   6.667776        1        1      4      1\n",
      "4        0  590  255000   7.467732        1        1      5      1\n",
      "...    ...  ...     ...        ...      ...      ...    ...    ...\n",
      "24388  585  742  255001  13.913711       12        4    176      2\n",
      "24389  585  738  255001  12.650958       12        4    177      2\n",
      "24390  585  746  255001  11.569930       12        4    179      2\n",
      "24391  585  741  255001   7.632603       12        4    180      2\n",
      "24392  585  743  255001  12.214476       12        4    181      2\n",
      "\n",
      "[24393 rows x 8 columns]\n",
      "\n",
      "Filtered Angle DataFrame:\n",
      "   src  dst    time       angle  src_mol  dst_mol  nh_id  label\n",
      "0    0  812  255000  120.540965        1        1      4      1\n",
      "1    0  813  255000  115.887955        1        1      5      1\n",
      "2    0  814  255000  172.370689        1        1      7      1\n",
      "3    0  815  255000  151.039706        1        1     15      1\n",
      "4    0  816  255000  167.839722        1        1     16      1\n"
     ]
    }
   ],
   "source": [
    "# Filter and label the distance DataFrame\n",
    "filtered_dist_df = dist_df[dist_df['distance'] <= 15].copy()\n",
    "filtered_dist_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Filter and label the angle DataFrame\n",
    "filtered_angle_df = angle_df[(angle_df['angle'] >= 105) & (angle_df['angle'] < 180)].copy()\n",
    "filtered_angle_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Combine src and dst values for consistent mapping\n",
    "combined_values = pd.concat([\n",
    "    filtered_dist_df['src'], filtered_dist_df['dst'], \n",
    "    filtered_angle_df['src'], filtered_angle_df['dst']\n",
    "])\n",
    "\n",
    "# Use factorize to assign numeric indices\n",
    "numeric_indices, _ = pd.factorize(combined_values)\n",
    "\n",
    "# Map src and dst directly to numeric indices using factorized output\n",
    "mapping = pd.Series(numeric_indices, index=combined_values).to_dict()\n",
    "\n",
    "# Replace src and dst with numeric indices\n",
    "for df in [filtered_dist_df, filtered_angle_df]:\n",
    "    df['src'] = df['src'].map(mapping)\n",
    "    df['dst'] = df['dst'].map(mapping)\n",
    "\n",
    "# Display the filtered DataFrames\n",
    "print(\"Filtered Distance DataFrame:\")\n",
    "print(filtered_dist_df)\n",
    "\n",
    "print(\"\\nFiltered Angle DataFrame:\")\n",
    "print(filtered_angle_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved updated DataFrame to DATA/HB/edges1.csv\n",
      "Saved updated DataFrame to DATA/HB/edges2.csv\n",
      "Updated Distance DataFrame:\n",
      "<bound method NDFrame.head of          idx  src  dst    time  label  ext_roll  nh_id\n",
      "0          0    0  586  255000      1         0      1\n",
      "1          1    0  587  255000      1         0      2\n",
      "2          2    0  588  255000      1         0      3\n",
      "3          3    0  589  255000      1         0      4\n",
      "4          4    0  590  255000      1         0      5\n",
      "...      ...  ...  ...     ...    ...       ...    ...\n",
      "24388  24388  585  742  255001      2         2    176\n",
      "24389  24389  585  738  255001      2         2    177\n",
      "24390  24390  585  746  255001      2         2    179\n",
      "24391  24391  585  741  255001      2         2    180\n",
      "24392  24392  585  743  255001      2         2    181\n",
      "\n",
      "[24393 rows x 7 columns]>\n",
      "\n",
      "Updated Angle DataFrame:\n",
      "   idx  src  dst    time  label  ext_roll  nh_id\n",
      "0    0    0  812  255000      1         0      4\n",
      "1    1    0  813  255000      1         0      5\n",
      "2    2    0  814  255000      1         0      7\n",
      "3    3    0  815  255000      1         0     15\n",
      "4    4    0  816  255000      1         0     16\n"
     ]
    }
   ],
   "source": [
    "# Process and save distance DataFrame\n",
    "final_dist_df = process_and_save_dataframe(filtered_dist_df, 'DATA/HB/edges1.csv')\n",
    "\n",
    "# Process and save angle DataFrame\n",
    "final_angle_df = process_and_save_dataframe(filtered_angle_df, 'DATA/HB/edges2.csv')\n",
    "\n",
    "# Display the first few rows of both DataFrames\n",
    "print(\"Updated Distance DataFrame:\")\n",
    "print(final_dist_df)\n",
    "\n",
    "print(\"\\nUpdated Angle DataFrame:\")\n",
    "print(final_angle_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract src and dst column features\n",
    "# src_feats = filtered_df[['src', 'src_mol']].rename(columns={'src': 'node', 'src_mol': 'mol'})\n",
    "# dst_feats = filtered_df[['dst', 'dst_mol']].rename(columns={'dst': 'node', 'dst_mol': 'mol'})\n",
    "\n",
    "# # Concatenate src and dst features\n",
    "# node_feats = pd.concat([src_feats, dst_feats])\n",
    "\n",
    "# # Drop duplicates\n",
    "# node_feats = node_feats.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# # Save to CSV\n",
    "# node_feats.to_csv('DATA/HB/node_feats.csv', index=False)\n",
    "\n",
    "# # Display the node features\n",
    "# print(node_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Encode nodes into unique integers\n",
    "# le_node = LabelEncoder()\n",
    "\n",
    "# # Fit the encoder on the combined 'src' and 'dst' columns from both dataframes\n",
    "# all_nodes = pd.concat([filtered_dist_df['src'], filtered_dist_df['dst'], filtered_angle_df['src'], filtered_angle_df['dst']])\n",
    "# le_node.fit(all_nodes)\n",
    "\n",
    "# # Transform the 'src' and 'dst' columns in both dataframes\n",
    "# filtered_dist_df['src'] = le_node.transform(filtered_dist_df['src'])\n",
    "# filtered_dist_df['dst'] = le_node.transform(filtered_dist_df['dst']) + filtered_dist_df['src'].max() + 1\n",
    "\n",
    "# filtered_angle_df['src'] = le_node.transform(filtered_angle_df['src'])\n",
    "# filtered_angle_df['dst'] = le_node.transform(filtered_angle_df['dst']) + filtered_angle_df['src'].max() + 1\n",
    "\n",
    "# # Display the first few rows of each dataframe\n",
    "# print(filtered_dist_df)\n",
    "# print(filtered_angle_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get unique nodes from node_1, node_2, and node_3 columns\n",
    "# unique_nodes_1 = filtered_df['src'].unique()\n",
    "# unique_nodes_2 = filtered_df['dst'].unique()\n",
    "\n",
    "# # Assign a color for each group (e.g., tab10 colormap)\n",
    "# color_1 = plt.cm.tab10(0)  # Color for node_1 group\n",
    "# color_2 = plt.cm.tab10(1)  # Color for node_2 group\n",
    "# color_3 = plt.cm.tab10(2)  # Color for node_3 group\n",
    "\n",
    "# # Create a combined color map based on the node groups\n",
    "# node_colors = {}\n",
    "# for node in unique_nodes_1:\n",
    "#     node_colors[node] = color_1\n",
    "# for node in unique_nodes_2:\n",
    "#     node_colors[node] = color_2\n",
    "\n",
    "\n",
    "# # Create a graph\n",
    "# G = nx.Graph()\n",
    "\n",
    "# # Add edges between node_1 and node_2\n",
    "# edges_1_2 = filtered_df[['node_1', 'node_2']].values.tolist()\n",
    "# G.add_edges_from(edges_1_2)\n",
    "\n",
    "# # Add edges between node_1 and node_3\n",
    "# edges_1_3 = filtered_df[['node_1', 'node_3']].values.tolist()\n",
    "# G.add_edges_from(edges_1_3)\n",
    "\n",
    "# # Add edges between node_2 and node_3 (these will be bold)\n",
    "# edges_2_3 = filtered_df[['node_2', 'node_3']].values.tolist()\n",
    "# G.add_edges_from(edges_2_3)\n",
    "\n",
    "# # Define the layout for the graph\n",
    "# pos = nx.spring_layout(G)\n",
    "\n",
    "# # Separate edges into normal and bold\n",
    "# normal_edges = edges_1_2 + edges_1_3\n",
    "# bold_edges = edges_2_3\n",
    "\n",
    "# # Plot the graph\n",
    "# plt.figure(figsize=(8, 4))\n",
    "# nx.draw(\n",
    "#     G,\n",
    "#     pos,\n",
    "#     with_labels=True,\n",
    "#     node_size=500,\n",
    "#     node_color=[node_colors[node] for node in G.nodes()],\n",
    "#     font_size=10,\n",
    "#     font_weight='bold',\n",
    "#     edge_color='gray',\n",
    "#     edgelist=normal_edges,\n",
    "#     width=1  # Normal edges width\n",
    "# )\n",
    "\n",
    "# # Draw the bold edges separately\n",
    "# nx.draw_networkx_edges(\n",
    "#     G,\n",
    "#     pos,\n",
    "#     edgelist=bold_edges,\n",
    "#     width=2,  # Bold edges width\n",
    "#     edge_color='black'\n",
    "# )\n",
    "\n",
    "# plt.title('Graph')\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphenv",
   "language": "python",
   "name": "graphenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
