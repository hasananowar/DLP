{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.spatial.distance import cdist\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example DataFrame with columns X, Y, Z, Atom_Name, Residue_Name, Residue_ID, Atom_Type, and Timeframe\n",
    "# Load nodes for all timesteps\n",
    "filepath = \"/home/mhanowar/Downloads/HB1000frames.csv\"  # Replace with the actual file path\n",
    "data = pd.read_csv(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>Atom_Name</th>\n",
       "      <th>Residue_Name</th>\n",
       "      <th>Residue_ID</th>\n",
       "      <th>Atom_Type</th>\n",
       "      <th>time</th>\n",
       "      <th>node</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.759892</td>\n",
       "      <td>2.253709</td>\n",
       "      <td>33.260902</td>\n",
       "      <td>C1</td>\n",
       "      <td>CSP</td>\n",
       "      <td>1</td>\n",
       "      <td>cb</td>\n",
       "      <td>255000</td>\n",
       "      <td>C1_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.862613</td>\n",
       "      <td>3.581455</td>\n",
       "      <td>34.023949</td>\n",
       "      <td>C2</td>\n",
       "      <td>CSP</td>\n",
       "      <td>1</td>\n",
       "      <td>cb</td>\n",
       "      <td>255000</td>\n",
       "      <td>C2_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.457548</td>\n",
       "      <td>4.321817</td>\n",
       "      <td>34.003315</td>\n",
       "      <td>C3</td>\n",
       "      <td>CSP</td>\n",
       "      <td>1</td>\n",
       "      <td>cb</td>\n",
       "      <td>255000</td>\n",
       "      <td>C3_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.981806</td>\n",
       "      <td>4.421790</td>\n",
       "      <td>32.537914</td>\n",
       "      <td>C4</td>\n",
       "      <td>CSP</td>\n",
       "      <td>1</td>\n",
       "      <td>cb</td>\n",
       "      <td>255000</td>\n",
       "      <td>C4_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.038748</td>\n",
       "      <td>3.091581</td>\n",
       "      <td>31.915064</td>\n",
       "      <td>O5</td>\n",
       "      <td>CSP</td>\n",
       "      <td>1</td>\n",
       "      <td>ob</td>\n",
       "      <td>255000</td>\n",
       "      <td>O5_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612595</th>\n",
       "      <td>21.328222</td>\n",
       "      <td>68.733505</td>\n",
       "      <td>52.952137</td>\n",
       "      <td>H8</td>\n",
       "      <td>SFL</td>\n",
       "      <td>14</td>\n",
       "      <td>ha</td>\n",
       "      <td>255099</td>\n",
       "      <td>H8_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612596</th>\n",
       "      <td>23.051521</td>\n",
       "      <td>68.403755</td>\n",
       "      <td>54.800755</td>\n",
       "      <td>H9</td>\n",
       "      <td>SFL</td>\n",
       "      <td>14</td>\n",
       "      <td>ha</td>\n",
       "      <td>255099</td>\n",
       "      <td>H9_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612597</th>\n",
       "      <td>20.372837</td>\n",
       "      <td>61.473118</td>\n",
       "      <td>59.333237</td>\n",
       "      <td>H10</td>\n",
       "      <td>SFL</td>\n",
       "      <td>14</td>\n",
       "      <td>ha</td>\n",
       "      <td>255099</td>\n",
       "      <td>H10_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612598</th>\n",
       "      <td>21.975138</td>\n",
       "      <td>58.681892</td>\n",
       "      <td>56.545349</td>\n",
       "      <td>H11</td>\n",
       "      <td>SFL</td>\n",
       "      <td>14</td>\n",
       "      <td>ha</td>\n",
       "      <td>255099</td>\n",
       "      <td>H11_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612599</th>\n",
       "      <td>21.290087</td>\n",
       "      <td>59.312321</td>\n",
       "      <td>58.949863</td>\n",
       "      <td>H12</td>\n",
       "      <td>SFL</td>\n",
       "      <td>14</td>\n",
       "      <td>ha</td>\n",
       "      <td>255099</td>\n",
       "      <td>H12_14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>612600 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                X          Y          Z Atom_Name Residue_Name  Residue_ID  \\\n",
       "0       12.759892   2.253709  33.260902        C1          CSP           1   \n",
       "1       12.862613   3.581455  34.023949        C2          CSP           1   \n",
       "2       11.457548   4.321817  34.003315        C3          CSP           1   \n",
       "3       10.981806   4.421790  32.537914        C4          CSP           1   \n",
       "4       11.038748   3.091581  31.915064        O5          CSP           1   \n",
       "...           ...        ...        ...       ...          ...         ...   \n",
       "612595  21.328222  68.733505  52.952137        H8          SFL          14   \n",
       "612596  23.051521  68.403755  54.800755        H9          SFL          14   \n",
       "612597  20.372837  61.473118  59.333237       H10          SFL          14   \n",
       "612598  21.975138  58.681892  56.545349       H11          SFL          14   \n",
       "612599  21.290087  59.312321  58.949863       H12          SFL          14   \n",
       "\n",
       "       Atom_Type    time    node  \n",
       "0             cb  255000    C1_1  \n",
       "1             cb  255000    C2_1  \n",
       "2             cb  255000    C3_1  \n",
       "3             cb  255000    C4_1  \n",
       "4             ob  255000    O5_1  \n",
       "...          ...     ...     ...  \n",
       "612595        ha  255099   H8_14  \n",
       "612596        ha  255099   H9_14  \n",
       "612597        ha  255099  H10_14  \n",
       "612598        ha  255099  H11_14  \n",
       "612599        ha  255099  H12_14  \n",
       "\n",
       "[612600 rows x 9 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the dataframe based on Timeframe\n",
    "df = data.loc[data['Timeframe'] < 255100].copy()\n",
    "df.rename(columns={\"Timeframe\": \"time\"}, inplace=True)\n",
    "\n",
    "# Add a combined 'node' column\n",
    "df['node'] = df.apply(lambda row: f\"{row['Atom_Name']}_{row['Residue_ID']}\", axis=1)\n",
    "# Display the updated dataframe\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select rows where Residue_ID is 5 and Atom_Type is either 'o' or 'os'\n",
    "# df1 = df[(df['Residue_ID'] == 5) & df['Atom_Type'].isin(['o', 'os'])].reset_index(drop=True)\n",
    "# Select all O Atoms\n",
    "# Select relevant atom types and residue names for calculations\n",
    "df1 = df[df['Atom_Name'].str.startswith('O')].reset_index(drop=True)\n",
    "df2 = df[(df['Residue_Name'] == 'CSP') & (df['Atom_Type'] == 'n')].reset_index(drop=True)\n",
    "df3 = df[(df['Residue_Name'] == 'CSP') & (df['Atom_Type'] == 'hn')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def calculate_angle(vec1, vec2):\n",
    "    \"\"\"Calculate angle between two vectors.\"\"\"\n",
    "    cos_theta = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "    angle_rad = np.arccos(np.clip(cos_theta, -1.0, 1.0))\n",
    "    return np.degrees(angle_rad)\n",
    "\n",
    "def calculate_distance(row1, row2):\n",
    "    \"\"\"Calculate Euclidean distance.\"\"\"\n",
    "    return np.linalg.norm(np.array([row1.X, row1.Y, row1.Z]) - np.array([row2.X, row2.Y, row2.Z]))\n",
    "\n",
    "def process_results(df):\n",
    "    \"\"\"Process DataFrame to add molecular IDs, unique nh_id, and labels.\"\"\"\n",
    "    df['src_mol'] = df['src'].apply(lambda x: int(x.split('_')[1]))\n",
    "    df['dst_mol'] = df['dst'].apply(lambda x: int(x.split('_')[1]))\n",
    "    df['nh_id'] = pd.factorize(df['dst'])[0] + 1\n",
    "    df['label'] = np.where(\n",
    "        (df['src_mol'].between(5, 14)) & (df['dst_mol'].between(1, 4)), 2, 1\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# Function to process DataFrame and save it to a CSV file\n",
    "def process_and_save_dataframe(df, filename):\n",
    "    \"\"\"\n",
    "    Process the input DataFrame to add 'ext_roll' and 'idx' columns.\n",
    "    Convert all columns to integers before saving.\n",
    "    Save the processed DataFrame to a specified CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame\n",
    "    - filename (str): Output file path\n",
    "    \"\"\"\n",
    "    num_rows = len(df)\n",
    "\n",
    "    # Initialize 'ext_roll' column with zeros\n",
    "    df['ext_roll'] = 0\n",
    "\n",
    "    # Assign 1 to the middle 15% rows and 2 to the last 15% rows\n",
    "    df.loc[int(num_rows * 0.7):int(num_rows * 0.85) - 1, 'ext_roll'] = 1\n",
    "    df.loc[int(num_rows * 0.85):, 'ext_roll'] = 2\n",
    "\n",
    "    # Insert an 'idx' column at the beginning\n",
    "    df.insert(0, 'idx', range(len(df)))\n",
    "\n",
    "    # Reindex and retain only the required columns\n",
    "    df = df[['idx', 'src', 'dst', 'time', 'label', 'ext_roll', 'nh_id']]\n",
    "\n",
    "    # Convert all columns to integers\n",
    "    for col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Save the updated DataFrame to the specified CSV file\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Saved updated DataFrame to {filename}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            src     dst    time   distance  src_mol  dst_mol  nh_id  label\n",
      "0          O5_1   N11_1  255000   4.435484        1        1      1      1\n",
      "1          O5_1   N23_1  255000   5.677049        1        1      2      1\n",
      "2          O5_1   N35_1  255000   6.328246        1        1      3      1\n",
      "3          O5_1   N55_1  255000   6.667776        1        1      4      1\n",
      "4          O5_1   N67_1  255000   7.467732        1        1      5      1\n",
      "...         ...     ...     ...        ...      ...      ...    ...    ...\n",
      "12873595  O2_14  N727_4  255099  79.479108       14        4    212      2\n",
      "12873596  O2_14  N739_4  255099  75.781733       14        4    213      2\n",
      "12873597  O2_14  N759_4  255099  75.197622       14        4    214      2\n",
      "12873598  O2_14  N771_4  255099  84.087391       14        4    215      2\n",
      "12873599  O2_14  N783_4  255099  83.915797       14        4    216      2\n",
      "\n",
      "[12873600 rows x 8 columns]\n",
      "            src     dst    time       angle  src_mol  dst_mol  nh_id  label\n",
      "0          O5_1    H9_1  255000   61.040505        1        1      1      1\n",
      "1          O5_1   H19_1  255000   73.524710        1        1      2      1\n",
      "2          O5_1   H29_1  255000   88.194570        1        1      3      1\n",
      "3          O5_1   H46_1  255000  120.540965        1        1      4      1\n",
      "4          O5_1   H56_1  255000  115.887955        1        1      5      1\n",
      "...         ...     ...     ...         ...      ...      ...    ...    ...\n",
      "12873595  O2_14  H611_4  255099  166.764098       14        4    212      2\n",
      "12873596  O2_14  H621_4  255099   62.206380       14        4    213      2\n",
      "12873597  O2_14  H638_4  255099   99.980679       14        4    214      2\n",
      "12873598  O2_14  H648_4  255099  137.762045       14        4    215      2\n",
      "12873599  O2_14  H658_4  255099   95.823211       14        4    216      2\n",
      "\n",
      "[12873600 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Calculate angles and distances\n",
    "distance_results = []\n",
    "angle_results = []\n",
    "\n",
    "for t in df1['time'].unique():\n",
    "    df1_time = df1[df1['time'] == t].reset_index(drop=True)\n",
    "    df2_time = df2[df2['time'] == t].reset_index(drop=True)\n",
    "    df3_time = df3[df3['time'] == t].reset_index(drop=True)\n",
    "\n",
    "    for row1 in df1_time.itertuples(index=False):\n",
    "        for idx, row3 in df3_time.iterrows():\n",
    "            if idx < len(df2_time):\n",
    "                row2 = df2_time.loc[idx]\n",
    "\n",
    "                # Vectors and calculations\n",
    "                vec3_to_df1 = np.array([row1.X - row3.X, row1.Y - row3.Y, row1.Z - row3.Z])\n",
    "                vec3_to_df2 = np.array([row2['X'] - row3.X, row2['Y'] - row3.Y, row2['Z'] - row3.Z])\n",
    "                angle = calculate_angle(vec3_to_df1, vec3_to_df2)\n",
    "                distance = calculate_distance(row1, row2)\n",
    "\n",
    "                # Append results\n",
    "                distance_results.append({'src': row1.node, 'dst': row2['node'], 'time': t, 'distance': distance})\n",
    "                angle_results.append({'src': row1.node, 'dst': row3['node'], 'time': t, 'angle': angle})\n",
    "\n",
    "# Convert results to DataFrames\n",
    "dist_df = process_results(pd.DataFrame(distance_results))\n",
    "angle_df = process_results(pd.DataFrame(angle_results))\n",
    "\n",
    "# Display DataFrames\n",
    "print(dist_df)\n",
    "print(angle_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Distance DataFrame:\n",
      "          src     dst    time  distance  src_mol  dst_mol  nh_id  label\n",
      "0        O5_1   N79_1  255000  3.043924        1        1      6      1\n",
      "1        O8_1   N11_1  255000  2.339837        1        1      1      1\n",
      "2       O10_1   N11_1  255000  2.352643        1        1      1      1\n",
      "3       O10_1   N79_1  255000  3.010041        1        1      6      1\n",
      "4       O20_1   N23_1  255000  2.250064        1        1      2      1\n",
      "...       ...     ...     ...       ...      ...      ...    ...    ...\n",
      "54293  O780_4  N783_4  255099  2.224148        4        4    216      1\n",
      "54294  O782_4  N771_4  255099  3.358267        4        4    215      1\n",
      "54295  O782_4  N783_4  255099  2.294585        4        4    216      1\n",
      "54296   O2_11  N407_1  255099  2.896783       11        1     28      2\n",
      "54297   O2_11  N475_1  255099  2.937560       11        1     33      2\n",
      "\n",
      "[54298 rows x 8 columns]\n",
      "\n",
      "Filtered Angle DataFrame:\n",
      "           src     dst    time       angle  src_mol  dst_mol  nh_id  label\n",
      "0         O5_1   H83_1  255000  172.370689        1        1      7      1\n",
      "1         O5_1  H177_1  255000  151.039706        1        1     15      1\n",
      "2         O5_1  H194_1  255000  167.839722        1        1     16      1\n",
      "3         O5_1  H268_1  255000  162.508433        1        1     22      1\n",
      "4         O5_1  H305_1  255000  148.477798        1        1     25      1\n",
      "...        ...     ...     ...         ...      ...      ...    ...    ...\n",
      "1820509  O2_14  H342_4  255099  142.582332       14        4    190      2\n",
      "1820510  O2_14  H352_4  255099  156.803905       14        4    191      2\n",
      "1820511  O2_14  H453_4  255099  157.656526       14        4    199      2\n",
      "1820512  O2_14  H611_4  255099  166.764098       14        4    212      2\n",
      "1820513  O2_14  H648_4  255099  137.762045       14        4    215      2\n",
      "\n",
      "[1820514 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filter and label the distance DataFrame\n",
    "filtered_dist_df = dist_df[dist_df['distance'] <= 3.5].copy()\n",
    "filtered_dist_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Filter and label the angle DataFrame\n",
    "filtered_angle_df = angle_df[(angle_df['angle'] >= 135) & (angle_df['angle'] < 180)].copy()\n",
    "filtered_angle_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "# Display the filtered DataFrames\n",
    "print(\"Filtered Distance DataFrame:\")\n",
    "print(filtered_dist_df)\n",
    "\n",
    "print(\"\\nFiltered Angle DataFrame:\")\n",
    "print(filtered_angle_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Distance DataFrame:\n",
      "         src     dst    time  distance  src_mol  dst_mol  nh_id  label\n",
      "0      O10_1   N79_1  255000  3.010041        1        1      6      1\n",
      "1     O184_1  N255_1  255000  3.252512        1        1     18      1\n",
      "2     O210_1  N231_1  255000  2.668763        1        1     16      1\n",
      "3     O284_1  N363_1  255000  3.411373        1        1     25      1\n",
      "4     O406_1  N451_1  255000  3.048154        1        1     31      1\n",
      "...      ...     ...     ...       ...      ...      ...    ...    ...\n",
      "4155  O430_4  N451_4  255099  3.339441        4        4    193      1\n",
      "4156  O518_4  N539_4  255099  3.117341        4        4    199      1\n",
      "4157  O626_4  N695_4  255099  2.918977        4        4    210      1\n",
      "4158   O2_11  N407_1  255099  2.896783       11        1     28      2\n",
      "4159   O2_11  N475_1  255099  2.937560       11        1     33      2\n",
      "\n",
      "[4160 rows x 8 columns]\n",
      "\n",
      "Filtered Angle DataFrame:\n",
      "         src     dst    time       angle  src_mol  dst_mol  nh_id  label\n",
      "0      O10_1   H66_1  255000  161.759281        1        1      6      1\n",
      "1     O184_1  H214_1  255000  136.799665        1        1     18      1\n",
      "2     O210_1  H194_1  255000  153.506310        1        1     16      1\n",
      "3     O284_1  H305_1  255000  146.807099        1        1     25      1\n",
      "4     O406_1  H379_1  255000  165.675379        1        1     31      1\n",
      "...      ...     ...     ...         ...      ...      ...    ...    ...\n",
      "4155  O430_4  H379_4  255099  154.582311        4        4    193      1\n",
      "4156  O518_4  H453_4  255099  151.279809        4        4    199      1\n",
      "4157  O626_4  H584_4  255099  166.260034        4        4    210      1\n",
      "4158   O2_11  H342_1  255099  165.328913       11        1     28      2\n",
      "4159   O2_11  H399_1  255099  138.959952       11        1     33      2\n",
      "\n",
      "[4160 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Find the intersection of rows based on 'time', 'src', and 'nh_id'\n",
    "common_keys = pd.merge(\n",
    "    filtered_dist_df[['time', 'src', 'nh_id']],\n",
    "    filtered_angle_df[['time', 'src', 'nh_id']],\n",
    "    on=['time', 'src', 'nh_id']\n",
    ")\n",
    "\n",
    "# Filter rows in filtered_dist_df based on the common keys\n",
    "filtered_dist_df = filtered_dist_df.merge(common_keys, on=['time', 'src', 'nh_id'])\n",
    "\n",
    "# Filter rows in filtered_angle_df based on the common keys\n",
    "filtered_angle_df = filtered_angle_df.merge(common_keys, on=['time', 'src', 'nh_id'])\n",
    "\n",
    "# Display the filtered DataFrames\n",
    "print(\"Filtered Distance DataFrame:\")\n",
    "print(filtered_dist_df)\n",
    "\n",
    "print(\"\\nFiltered Angle DataFrame:\")\n",
    "print(filtered_angle_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Distance DataFrame:\n",
      "      src  dst    time  distance  src_mol  dst_mol  nh_id  label\n",
      "0       1  101  255000  3.010041        1        1      6      1\n",
      "1       2  102  255000  3.252512        1        1     18      1\n",
      "2       3  103  255000  2.668763        1        1     16      1\n",
      "3       4  104  255000  3.411373        1        1     25      1\n",
      "4       5  105  255000  3.048154        1        1     31      1\n",
      "...   ...  ...     ...       ...      ...      ...    ...    ...\n",
      "4155   54  156  255099  3.339441        4        4    193      1\n",
      "4156   36  136  255099  3.117341        4        4    199      1\n",
      "4157   37  138  255099  2.918977        4        4    210      1\n",
      "4158   39  140  255099  2.896783       11        1     28      2\n",
      "4159   39  149  255099  2.937560       11        1     33      2\n",
      "\n",
      "[4160 rows x 8 columns]\n",
      "\n",
      "Filtered Angle DataFrame:\n",
      "      src  dst    time       angle  src_mol  dst_mol  nh_id  label\n",
      "0       1  188  255000  161.759281        1        1      6      1\n",
      "1       2  189  255000  136.799665        1        1     18      1\n",
      "2       3  190  255000  153.506310        1        1     16      1\n",
      "3       4  191  255000  146.807099        1        1     25      1\n",
      "4       5  192  255000  165.675379        1        1     31      1\n",
      "...   ...  ...     ...         ...      ...      ...    ...    ...\n",
      "4155   54  243  255099  154.582311        4        4    193      1\n",
      "4156   36  223  255099  151.279809        4        4    199      1\n",
      "4157   37  225  255099  166.260034        4        4    210      1\n",
      "4158   39  227  255099  165.328913       11        1     28      2\n",
      "4159   39  236  255099  138.959952       11        1     33      2\n",
      "\n",
      "[4160 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Combine src and dst values for consistent mapping\n",
    "combined_values = pd.concat([\n",
    "    filtered_dist_df['src'], filtered_dist_df['dst'], \n",
    "    filtered_angle_df['src'], filtered_angle_df['dst']\n",
    "])\n",
    "\n",
    "# Use factorize to assign numeric indices starting from 0\n",
    "numeric_indices, _ = pd.factorize(combined_values)\n",
    "\n",
    "# Add 1 to ensure indices start from 1\n",
    "numeric_indices += 1\n",
    "\n",
    "# Map src and dst directly to numeric indices using factorized output\n",
    "mapping = pd.Series(numeric_indices, index=combined_values).to_dict()\n",
    "\n",
    "# Replace src and dst with numeric indices starting from 1\n",
    "for df in [filtered_dist_df, filtered_angle_df]:\n",
    "    df['src'] = df['src'].map(mapping)\n",
    "    df['dst'] = df['dst'].map(mapping)\n",
    "\n",
    "# Display the filtered DataFrames\n",
    "print(\"Filtered Distance DataFrame:\")\n",
    "print(filtered_dist_df)\n",
    "\n",
    "print(\"\\nFiltered Angle DataFrame:\")\n",
    "print(filtered_angle_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved updated DataFrame to DATA/HB/edges1.csv\n",
      "Saved updated DataFrame to DATA/HB/edges2.csv\n",
      "Updated Distance DataFrame:\n",
      "       idx  src  dst    time  label  ext_roll  nh_id\n",
      "0        0    1  101  255000      1         0      6\n",
      "1        1    2  102  255000      1         0     18\n",
      "2        2    3  103  255000      1         0     16\n",
      "3        3    4  104  255000      1         0     25\n",
      "4        4    5  105  255000      1         0     31\n",
      "...    ...  ...  ...     ...    ...       ...    ...\n",
      "4155  4155   54  156  255099      1         2    193\n",
      "4156  4156   36  136  255099      1         2    199\n",
      "4157  4157   37  138  255099      1         2    210\n",
      "4158  4158   39  140  255099      2         2     28\n",
      "4159  4159   39  149  255099      2         2     33\n",
      "\n",
      "[4160 rows x 7 columns]\n",
      "\n",
      "Updated Angle DataFrame:\n",
      "       idx  src  dst    time  label  ext_roll  nh_id\n",
      "0        0    1  188  255000      1         0      6\n",
      "1        1    2  189  255000      1         0     18\n",
      "2        2    3  190  255000      1         0     16\n",
      "3        3    4  191  255000      1         0     25\n",
      "4        4    5  192  255000      1         0     31\n",
      "...    ...  ...  ...     ...    ...       ...    ...\n",
      "4155  4155   54  243  255099      1         2    193\n",
      "4156  4156   36  223  255099      1         2    199\n",
      "4157  4157   37  225  255099      1         2    210\n",
      "4158  4158   39  227  255099      2         2     28\n",
      "4159  4159   39  236  255099      2         2     33\n",
      "\n",
      "[4160 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_393770/2717949617.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
      "/tmp/ipykernel_393770/2717949617.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
      "/tmp/ipykernel_393770/2717949617.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
      "/tmp/ipykernel_393770/2717949617.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
      "/tmp/ipykernel_393770/2717949617.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
      "/tmp/ipykernel_393770/2717949617.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
      "/tmp/ipykernel_393770/2717949617.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
      "/tmp/ipykernel_393770/2717949617.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
      "/tmp/ipykernel_393770/2717949617.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
      "/tmp/ipykernel_393770/2717949617.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
      "/tmp/ipykernel_393770/2717949617.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
      "/tmp/ipykernel_393770/2717949617.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
      "/tmp/ipykernel_393770/2717949617.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
      "/tmp/ipykernel_393770/2717949617.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Process and save distance DataFrame\n",
    "final_dist_df = process_and_save_dataframe(filtered_dist_df, 'DATA/HB/edges1.csv')\n",
    "\n",
    "# Process and save angle DataFrame\n",
    "final_angle_df = process_and_save_dataframe(filtered_angle_df, 'DATA/HB/edges2.csv')\n",
    "\n",
    "# Display the first few rows of both DataFrames\n",
    "print(\"Updated Distance DataFrame:\")\n",
    "print(final_dist_df)\n",
    "\n",
    "print(\"\\nUpdated Angle DataFrame:\")\n",
    "print(final_angle_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "new_dist_df = filtered_dist_df.copy()\n",
    "new_angle_df = filtered_angle_df.copy()\n",
    "# Combine src and dst columns from both DataFrames to ensure consistent mapping\n",
    "combined_values = pd.concat([\n",
    "    new_dist_df [['src', 'dst']],\n",
    "    new_angle_df[['src', 'dst']]\n",
    "])\n",
    "\n",
    "# Fit an OrdinalEncoder on the combined src and dst values\n",
    "encoder = OrdinalEncoder(dtype=int)\n",
    "encoder.fit(combined_values)\n",
    "\n",
    "# Apply the encoder to the src and dst columns in both DataFrames\n",
    "new_dist_df[['src', 'dst']] = encoder.transform(new_dist_df[['src', 'dst']]) + 1  # Start from 1\n",
    "new_angle_df[['src', 'dst']] = encoder.transform(new_angle_df[['src', 'dst']]) + 1  # Start from 1\n",
    "\n",
    "# Display the updated DataFrames\n",
    "print(\"Updated new_dist_df:\")\n",
    "print(new_dist_df)\n",
    "\n",
    "print(\"\\nUpdated new_angle_df:\")\n",
    "print(new_angle_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and save distance DataFrame\n",
    "renew_dist_df = process_and_save_dataframe(new_dist_df, 'DATA/HB/edges3.csv')\n",
    "\n",
    "# Process and save angle DataFrame\n",
    "renew_angle_df = process_and_save_dataframe(new_angle_df, 'DATA/HB/edges4.csv')\n",
    "\n",
    "# Display the first few rows of both DataFrames\n",
    "print(\"Updated Distance DataFrame:\")\n",
    "print(renew_dist_df)\n",
    "\n",
    "print(\"\\nUpdated Angle DataFrame:\")\n",
    "print(renew_angle_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract src and dst column features\n",
    "# src_feats = filtered_df[['src', 'src_mol']].rename(columns={'src': 'node', 'src_mol': 'mol'})\n",
    "# dst_feats = filtered_df[['dst', 'dst_mol']].rename(columns={'dst': 'node', 'dst_mol': 'mol'})\n",
    "\n",
    "# # Concatenate src and dst features\n",
    "# node_feats = pd.concat([src_feats, dst_feats])\n",
    "\n",
    "# # Drop duplicates\n",
    "# node_feats = node_feats.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# # Save to CSV\n",
    "# node_feats.to_csv('DATA/HB/node_feats.csv', index=False)\n",
    "\n",
    "# # Display the node features\n",
    "# print(node_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Encode nodes into unique integers\n",
    "# le_node = LabelEncoder()\n",
    "\n",
    "# # Fit the encoder on the combined 'src' and 'dst' columns from both dataframes\n",
    "# all_nodes = pd.concat([filtered_dist_df['src'], filtered_dist_df['dst'], filtered_angle_df['src'], filtered_angle_df['dst']])\n",
    "# le_node.fit(all_nodes)\n",
    "\n",
    "# # Transform the 'src' and 'dst' columns in both dataframes\n",
    "# filtered_dist_df['src'] = le_node.transform(filtered_dist_df['src'])\n",
    "# filtered_dist_df['dst'] = le_node.transform(filtered_dist_df['dst']) + filtered_dist_df['src'].max() + 1\n",
    "\n",
    "# filtered_angle_df['src'] = le_node.transform(filtered_angle_df['src'])\n",
    "# filtered_angle_df['dst'] = le_node.transform(filtered_angle_df['dst']) + filtered_angle_df['src'].max() + 1\n",
    "\n",
    "# # Display the first few rows of each dataframe\n",
    "# print(filtered_dist_df)\n",
    "# print(filtered_angle_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get unique nodes from node_1, node_2, and node_3 columns\n",
    "# unique_nodes_1 = filtered_df['src'].unique()\n",
    "# unique_nodes_2 = filtered_df['dst'].unique()\n",
    "\n",
    "# # Assign a color for each group (e.g., tab10 colormap)\n",
    "# color_1 = plt.cm.tab10(0)  # Color for node_1 group\n",
    "# color_2 = plt.cm.tab10(1)  # Color for node_2 group\n",
    "# color_3 = plt.cm.tab10(2)  # Color for node_3 group\n",
    "\n",
    "# # Create a combined color map based on the node groups\n",
    "# node_colors = {}\n",
    "# for node in unique_nodes_1:\n",
    "#     node_colors[node] = color_1\n",
    "# for node in unique_nodes_2:\n",
    "#     node_colors[node] = color_2\n",
    "\n",
    "\n",
    "# # Create a graph\n",
    "# G = nx.Graph()\n",
    "\n",
    "# # Add edges between node_1 and node_2\n",
    "# edges_1_2 = filtered_df[['node_1', 'node_2']].values.tolist()\n",
    "# G.add_edges_from(edges_1_2)\n",
    "\n",
    "# # Add edges between node_1 and node_3\n",
    "# edges_1_3 = filtered_df[['node_1', 'node_3']].values.tolist()\n",
    "# G.add_edges_from(edges_1_3)\n",
    "\n",
    "# # Add edges between node_2 and node_3 (these will be bold)\n",
    "# edges_2_3 = filtered_df[['node_2', 'node_3']].values.tolist()\n",
    "# G.add_edges_from(edges_2_3)\n",
    "\n",
    "# # Define the layout for the graph\n",
    "# pos = nx.spring_layout(G)\n",
    "\n",
    "# # Separate edges into normal and bold\n",
    "# normal_edges = edges_1_2 + edges_1_3\n",
    "# bold_edges = edges_2_3\n",
    "\n",
    "# # Plot the graph\n",
    "# plt.figure(figsize=(8, 4))\n",
    "# nx.draw(\n",
    "#     G,\n",
    "#     pos,\n",
    "#     with_labels=True,\n",
    "#     node_size=500,\n",
    "#     node_color=[node_colors[node] for node in G.nodes()],\n",
    "#     font_size=10,\n",
    "#     font_weight='bold',\n",
    "#     edge_color='gray',\n",
    "#     edgelist=normal_edges,\n",
    "#     width=1  # Normal edges width\n",
    "# )\n",
    "\n",
    "# # Draw the bold edges separately\n",
    "# nx.draw_networkx_edges(\n",
    "#     G,\n",
    "#     pos,\n",
    "#     edgelist=bold_edges,\n",
    "#     width=2,  # Bold edges width\n",
    "#     edge_color='black'\n",
    "# )\n",
    "\n",
    "# plt.title('Graph')\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphenv",
   "language": "python",
   "name": "graphenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
