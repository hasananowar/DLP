{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables: [('studies',), ('version_info',), ('study_directions',), ('study_user_attributes',), ('study_system_attributes',), ('trials',), ('trial_user_attributes',), ('trial_system_attributes',), ('trial_params',), ('trial_values',), ('trial_intermediate_values',), ('trial_heartbeats',), ('alembic_version',)]\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Path to your database file\n",
    "db_path = \"optuna.db\"\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Create a cursor object to interact with the database\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# List all tables in the database\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "print(\"Tables:\", tables)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     param_id  trial_id                param_name  param_value  \\\n",
      "0           1         2                        lr     0.002020   \n",
      "1           2         2              weight_decay     0.000025   \n",
      "2           3         2                   dropout     0.394411   \n",
      "3           4         3                        lr     0.000386   \n",
      "4           5         2               hidden_dims   128.000000   \n",
      "..        ...       ...                       ...          ...   \n",
      "139       140        16                 max_edges    70.000000   \n",
      "140       141        15  channel_expansion_factor     2.000000   \n",
      "141       142        16  channel_expansion_factor     4.000000   \n",
      "142       143        15             num_neighbors    30.000000   \n",
      "143       144        16             num_neighbors    30.000000   \n",
      "\n",
      "                                     distribution_json  \n",
      "0    {\"name\": \"FloatDistribution\", \"attributes\": {\"...  \n",
      "1    {\"name\": \"FloatDistribution\", \"attributes\": {\"...  \n",
      "2    {\"name\": \"FloatDistribution\", \"attributes\": {\"...  \n",
      "3    {\"name\": \"FloatDistribution\", \"attributes\": {\"...  \n",
      "4    {\"name\": \"IntDistribution\", \"attributes\": {\"lo...  \n",
      "..                                                 ...  \n",
      "139  {\"name\": \"IntDistribution\", \"attributes\": {\"lo...  \n",
      "140  {\"name\": \"IntDistribution\", \"attributes\": {\"lo...  \n",
      "141  {\"name\": \"IntDistribution\", \"attributes\": {\"lo...  \n",
      "142  {\"name\": \"IntDistribution\", \"attributes\": {\"lo...  \n",
      "143  {\"name\": \"IntDistribution\", \"attributes\": {\"lo...  \n",
      "\n",
      "[144 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Connect to the database\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Load a specific table into a DataFrame\n",
    "df = pd.read_sql_query(\"SELECT * FROM trial_params;\", conn)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n",
    "\n",
    "    # Save the updated DataFrame to the specified CSV file\n",
    "df.to_csv('optunadb', index=False)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'collections.OrderedDict'>\n",
      "Keys in the .pt file: odict_keys(['base_model.feat_encoder.time_encoder.w.weight', 'base_model.feat_encoder.time_encoder.w.bias', 'base_model.feat_encoder.feat_encoder.weight', 'base_model.feat_encoder.feat_encoder.bias', 'base_model.layernorm.weight', 'base_model.layernorm.bias', 'base_model.mlp_head.weight', 'base_model.mlp_head.bias', 'base_model.mixer_blocks.0.transformer_encoder.W_Q.weight', 'base_model.mixer_blocks.0.transformer_encoder.W_Q.bias', 'base_model.mixer_blocks.0.transformer_encoder.W_K.weight', 'base_model.mixer_blocks.0.transformer_encoder.W_K.bias', 'base_model.mixer_blocks.0.transformer_encoder.W_V.weight', 'base_model.mixer_blocks.0.transformer_encoder.W_V.bias', 'base_model.mixer_blocks.0.transformer_encoder.sdp_attn.scale', 'base_model.mixer_blocks.0.transformer_encoder.to_out.0.weight', 'base_model.mixer_blocks.0.transformer_encoder.to_out.0.bias', 'base_model.mixer_blocks.0.channel_layernorm.weight', 'base_model.mixer_blocks.0.channel_layernorm.bias', 'base_model.mixer_blocks.0.channel_forward.linear_0.weight', 'base_model.mixer_blocks.0.channel_forward.linear_0.bias', 'base_model.mixer_blocks.0.channel_forward.linear_1.weight', 'base_model.mixer_blocks.0.channel_forward.linear_1.bias', 'base_model.mixer_blocks.1.transformer_encoder.W_Q.weight', 'base_model.mixer_blocks.1.transformer_encoder.W_Q.bias', 'base_model.mixer_blocks.1.transformer_encoder.W_K.weight', 'base_model.mixer_blocks.1.transformer_encoder.W_K.bias', 'base_model.mixer_blocks.1.transformer_encoder.W_V.weight', 'base_model.mixer_blocks.1.transformer_encoder.W_V.bias', 'base_model.mixer_blocks.1.transformer_encoder.sdp_attn.scale', 'base_model.mixer_blocks.1.transformer_encoder.to_out.0.weight', 'base_model.mixer_blocks.1.transformer_encoder.to_out.0.bias', 'base_model.mixer_blocks.1.channel_layernorm.weight', 'base_model.mixer_blocks.1.channel_layernorm.bias', 'base_model.mixer_blocks.1.channel_forward.linear_0.weight', 'base_model.mixer_blocks.1.channel_forward.linear_0.bias', 'base_model.mixer_blocks.1.channel_forward.linear_1.weight', 'base_model.mixer_blocks.1.channel_forward.linear_1.bias', 'base_model.mixer_blocks.2.transformer_encoder.W_Q.weight', 'base_model.mixer_blocks.2.transformer_encoder.W_Q.bias', 'base_model.mixer_blocks.2.transformer_encoder.W_K.weight', 'base_model.mixer_blocks.2.transformer_encoder.W_K.bias', 'base_model.mixer_blocks.2.transformer_encoder.W_V.weight', 'base_model.mixer_blocks.2.transformer_encoder.W_V.bias', 'base_model.mixer_blocks.2.transformer_encoder.sdp_attn.scale', 'base_model.mixer_blocks.2.transformer_encoder.to_out.0.weight', 'base_model.mixer_blocks.2.transformer_encoder.to_out.0.bias', 'base_model.mixer_blocks.2.channel_layernorm.weight', 'base_model.mixer_blocks.2.channel_layernorm.bias', 'base_model.mixer_blocks.2.channel_forward.linear_0.weight', 'base_model.mixer_blocks.2.channel_forward.linear_0.bias', 'base_model.mixer_blocks.2.channel_forward.linear_1.weight', 'base_model.mixer_blocks.2.channel_forward.linear_1.bias', 'base_model.pad_projector.weight', 'base_model.pad_projector.bias', 'base_model.p_enc_1d_model_sum.penc.inv_freq', 'edge_predictor.src_fc.weight', 'edge_predictor.src_fc.bias', 'edge_predictor.dst_fc.weight', 'edge_predictor.dst_fc.bias', 'edge_predictor.out_fc.weight', 'edge_predictor.out_fc.bias'])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Load the .pt file\n",
    "data = torch.load(\"models/best_model_trial_8.pt\")\n",
    "\n",
    "# Check the type of the loaded object\n",
    "print(type(data))\n",
    "\n",
    "# If it's a dictionary, list the keys\n",
    "if isinstance(data, dict):\n",
    "    print(\"Keys in the .pt file:\", data.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphenv",
   "language": "python",
   "name": "graphenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
